{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "from zemberek import (\n",
    "    TurkishSpellChecker,\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-16 14:57:12,099 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 7.47469687461853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = [\"Yrn okua gidicem\",\n",
    "            \"Tmm, yarin havuza giricem ve aksama kadar yaticam :)\",\n",
    "            \"ah aynen ya annemde fark ettı siz evinizden cıkmayın diyo\",\n",
    "            \"gercek mı bu? Yuh! Artık unutulması bile beklenmiyo\",\n",
    "            \"Hayır hayat telaşm olmasa alacam buraları gökdelen dikicem.\",\n",
    "            \"yok hocam kesınlıkle oyle birşey yok\",\n",
    "            \"herseyi soyle hayatında olmaması gerek bence boyle ınsanların falan baskı yapıyosa\",\n",
    "            \"email adresim zemberek_python@loodos.com\",\n",
    "            \"Kredi başvrusu yapmk istiyrum.\",\n",
    "            \"Bankanizin hesp blgilerini ogrenmek istyorum.\"]\n",
    "\n",
    "morphology = TurkishMorphology.create_with_defaults()\n",
    "\n",
    "# SENTENCE NORMALIZATION\n",
    "normalizer = TurkishSentenceNormalizer(morphology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yrn okua gidicem\n",
      "yarin okula gidecegim \n",
      "\n",
      "Tmm, yarin havuza giricem ve aksama kadar yaticam :)\n",
      "tamam , yarin havuza girecegim ve aksama kadar yatacagim :) \n",
      "\n",
      "ah aynen ya annemde fark ettı siz evinizden cıkmayın diyo\n",
      "ah aynen ya annemde fark etti siz evinizden cikmayin diyor \n",
      "\n",
      "gercek mı bu? Yuh! Artık unutulması bile beklenmiyo\n",
      "gercek mi bu ? yuh ! artik unutulmasi bile beklenmiyor \n",
      "\n",
      "Hayır hayat telaşm olmasa alacam buraları gökdelen dikicem.\n",
      "hayir hayat telasi olmasa alacagim buralari gokdelen dikecegim . \n",
      "\n",
      "yok hocam kesınlıkle oyle birşey yok\n",
      "yok hocam kesinlikle oyle bir sey yok \n",
      "\n",
      "herseyi soyle hayatında olmaması gerek bence boyle ınsanların falan baskı yapıyosa\n",
      "herseyi soyle hayatinda olmamasi gerek bence boyle insanlarin falan baski yapiyorsa \n",
      "\n",
      "email adresim zemberek_python@loodos.com\n",
      "mail adresim zemberek_python@loodos.com \n",
      "\n",
      "Kredi başvrusu yapmk istiyrum.\n",
      "kredi basvurusu yapmak istiyorum . \n",
      "\n",
      "Bankanizin hesp blgilerini ogrenmek istyorum.\n",
      "bankanizin hesap bilgilerini ogrenmek istiyorum . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in examples:\n",
    "    print(example)\n",
    "    print(unidecode(normalizer.normalize(unidecode(example))), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = TurkishSpellChecker(morphology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okuyablirim ('okuyabilirim',)\n",
      "tartısıyor ('tartışıyor', 'tartılıyor')\n",
      "Ankar'ada (\"Ankara'da\", \"Ankara'ya\", \"Ankara'dan\", \"Ankara'ca\", \"Antara'da\", \"Ankara'na\", \"Angara'da\", \"Ankara'mda\", \"Ankaray'da\", \"Ankara'ma\", \"Ankaray'a\", \"Anakara'da\", \"Ankara'nda\")\n",
      "knlıca ('kanlıca', 'kanlıca', 'kılıca', 'kalıca', 'kınlıca', 'anlıca')\n",
      "yapablrim ()\n",
      "kıredi ('kredi', 'küredi')\n",
      "geldm ('geldi', 'geldim', 'gelem', 'gelim')\n",
      "geliyom ('geliyor', 'geliyim')\n",
      "aldm ('aldı', 'alım', 'aldım', 'alem', 'alim', 'alim', 'alam', 'aldi', 'aldo', 'alda', \"Al'dım\", \"Al'ım\", \"Aldo'm\", \"Aldi'm\", \"Al'dı\", \"Al'da\")\n",
      "asln ('asla', 'aslan', 'aslan', 'aslı', 'aslı', 'asli', 'aslen', 'asan', 'asın', 'aslin', \"As'la\", \"As'ın\", \"As'lı\", 'assn', 'aslın', 'asin', \"As'lın\", \"As'lan\", \"Aslı'n\")\n"
     ]
    }
   ],
   "source": [
    "li = [\"okuyablirim\", \"tartısıyor\", \"Ankar'ada\", \"knlıca\", \"yapablrim\", \"kıredi\", \"geldm\", \"geliyom\", \"aldm\", \"asln\"]\n",
    "for word in li:\n",
    "    #print(word + \" = \" + ' '.join(sc.suggest_for_word(word)))\n",
    "    print(word, sc.suggest_for_word(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = TurkishSentenceExtractor()\n",
    "text = \"İnsanoğlu aslında ne para ne sevgi ne kariyer ne şöhret ne de çevre ile sonsuza dek mutlu olabilecek bir \" \\\n",
    "       \"yapıya sahiptir. Dış kaynaklardan gelebilecek bu mutluluklar sadece belirli bir zaman için insanı mutlu \" \\\n",
    "       \"kılıyor. Kişi bu kaynakları elde ettiği zaman belirli bir dönem için kendini iyi hissediyor, ancak alışma \" \\\n",
    "       \"dönemine girdiği andan itibaren bu iyilik hali hızla tükeniyor. Mutlu olma sanatının özü bu değildir. Gerçek \" \\\n",
    "       \"mutluluk, kişinin her türlü olaya ve duruma karşı kendini pozitif tutarak mutlu hissedebilmesi halidir. Bu \" \\\n",
    "       \"davranış şeklini edinen insan, zor günlerde güçlü, mutlu günlerde zevk alan biri olur ve mutluluğu kalıcı \" \\\n",
    "       \"kılar. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['İnsanoğlu aslında ne para ne sevgi ne kariyer ne şöhret ne de çevre ile sonsuza dek mutlu olabilecek bir yapıya sahiptir.',\n",
       " 'Dış kaynaklardan gelebilecek bu mutluluklar sadece belirli bir zaman için insanı mutlu kılıyor.',\n",
       " 'Kişi bu kaynakları elde ettiği zaman belirli bir dönem için kendini iyi hissediyor, ancak alışma dönemine girdiği andan itibaren bu iyilik hali hızla tükeniyor.',\n",
       " 'Mutlu olma sanatının özü bu değildir.',\n",
       " 'Gerçek mutluluk, kişinin her türlü olaya ve duruma karşı kendini pozitif tutarak mutlu hissedebilmesi halidir.',\n",
       " 'Bu davranış şeklini edinen insan, zor günlerde güçlü, mutlu günlerde zevk alan biri olur ve mutluluğu kalıcı kılar.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = extractor.from_paragraph(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ankara:Noun, Prop] ankara:Noun+A3sg+da:Loc\n"
     ]
    }
   ],
   "source": [
    "# SINGLE WORD MORPHOLOGICAL ANALYSIS\n",
    "results = morphology.analyze(\"Ankara'da\")\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Yarın kar yağacak.\"\n",
    "analysis = morphology.analyze_sentence(sentence)\n",
    "after = morphology.disambiguate(sentence, analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before disambiguation\n",
      "WordAnalysis{input='Yarın', normalizedInput='yarın', analysisResults=[yarın:Adv] yarın:Adv [yarmak:Verb] yar:Verb+Imp+ın:A2pl [yar:Noun] yar:Noun+A3sg+ın:Gen [yar:Noun] yar:Noun+A3sg+ın:P2sg [yarı:Noun] yarı:Noun+A3sg+n:P2sg [yarın:Noun, Time] yarın:Noun+A3sg [yarı:Adj] yarı:Adj|Zero→Noun+A3sg+n:P2sg}\n",
      "Word = Yarın\n",
      "[yarın:Adv] yarın:Adv\n",
      "[yarmak:Verb] yar:Verb+Imp+ın:A2pl\n",
      "[yar:Noun] yar:Noun+A3sg+ın:Gen\n",
      "[yar:Noun] yar:Noun+A3sg+ın:P2sg\n",
      "[yarı:Noun] yarı:Noun+A3sg+n:P2sg\n",
      "[yarın:Noun, Time] yarın:Noun+A3sg\n",
      "[yarı:Adj] yarı:Adj|Zero→Noun+A3sg+n:P2sg\n",
      "WordAnalysis{input='kar', normalizedInput='kar', analysisResults=[karmak:Verb] kar:Verb+Imp+A2sg [kar:Noun] kar:Noun+A3sg [kâr:Noun] kar:Noun+A3sg}\n",
      "Word = kar\n",
      "[karmak:Verb] kar:Verb+Imp+A2sg\n",
      "[kar:Noun] kar:Noun+A3sg\n",
      "[kâr:Noun] kar:Noun+A3sg\n",
      "WordAnalysis{input='yağacak', normalizedInput='yağacak', analysisResults=[yağmak:Verb] yağ:Verb+acak:Fut+A3sg [yağmak:Verb] yağ:Verb|acak:FutPart→Adj}\n",
      "Word = yağacak\n",
      "[yağmak:Verb] yağ:Verb+acak:Fut+A3sg\n",
      "[yağmak:Verb] yağ:Verb|acak:FutPart→Adj\n",
      "WordAnalysis{input='.', normalizedInput='.', analysisResults=[.:Punc] .:Punc}\n",
      "Word = .\n",
      "[.:Punc] .:Punc\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBefore disambiguation\")\n",
    "for e in analysis:\n",
    "    print(e)\n",
    "    print(f\"Word = {e.inp}\")\n",
    "    for s in e:\n",
    "        print(s.format_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After disambiguation\n",
      "lemma:  yarın\n",
      "stem:  yarın\n",
      "lemma:  kar\n",
      "stem:  kar\n",
      "lemma:  yağ\n",
      "stem:  yağ\n",
      "lemma:  .\n",
      "stem:  .\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAfter disambiguation\")\n",
    "for s in after.best_analysis():\n",
    "    print(\"lemma: \", s.item.normalized_lemma())\n",
    "    print(\"stem: \",s.get_stem())\n",
    "    #print(s.format_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content =  Saat\n",
      "Type =  Word\n",
      "Start =  0\n",
      "Stop =  3 \n",
      "\n",
      "Content =  12:00\n",
      "Type =  Time\n",
      "Start =  5\n",
      "Stop =  9 \n",
      "\n",
      "Content =  .\n",
      "Type =  Punctuation\n",
      "Start =  10\n",
      "Stop =  10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZATION\n",
    "tokenizer = TurkishTokenizer.DEFAULT\n",
    "\n",
    "tokens = tokenizer.tokenize(\"Saat 12:00.\")\n",
    "for token in tokens:\n",
    "    print('Content = ', token.content)\n",
    "    print('Type = ', token.type_.name)\n",
    "    print('Start = ', token.start)\n",
    "    print('Stop = ', token.end, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
